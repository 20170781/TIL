# 5. Memory Hierarchy

## 5.1 Introduction

- 메모리 종류

  - **Cache**

  - **Main Memory**

  - **Secondary Memory (Disk)**

- **지역성 원칙**

  - **Temporal Locality** (시간적 지역성): 어떤 데이터가 참조되면, 곧바로 다시 참조될 가능성이 높다는 원칙

  - **Spatial Locality** (공간적 지역성): 하나의 데이터가 참조되면, 곧바로 그 주위의 데이터가 참조될 가능성이 높다는 원칙
  - 지역성의 이점을 활용하기 위해 Memory Hierarchy 활용

- **Memory Hierarchy**

  <img width="210" alt="image" src="https://user-images.githubusercontent.com/70627979/182009482-c4d6c57e-9343-4a08-9e69-a8d9203873b6.png">

  <img src="https://user-images.githubusercontent.com/70627979/182009384-ab0ac2ed-59cb-4852-8a18-2aa919d00cfd.png" alt="image" style="width:50%;" />

  - 빠른 메모리는 프로세서에 가깝게 두고, 느리고 싼 메모리를 그 아래에 두기
  - **목적: 사용자에게 가장 빠른 메모리의 접근 속도를 제공하면서, 동시에 가장 싼 메모리만큼의 용량을 제공**
  - hit는 캐시에서 데이터의 참조 성공, miss는 캐시에서 데이터의 참조 실패를 의미

  



## 5.2 Memory Technology

### Register

: CPU가 요청을 처리하는데 필요한 데이터 일시적으로 저장하는 기억장치



### SRAM (캐시)

: 속도가 빠른 장치와 느린 장치 사이에서 속도차에 따른 병목 현상을 완화하기 위한 범용 메모리

- read/write 가능한 접근 포트가 하나 있는 메모리 배열로 구성된 단순한 집적 회로
- 어떤 데이터든지 접근시간은 같다
- 리프레시가 필요 없어, 접근 시간은 사이클 시간과 거의 같다
- 비트당 6~8개의 트랜지스터 사용



### DRAM (메인 메모리)

: 컴퓨터에서 수치, 명령, 자료 등을 기억하는 주 기억장치

<img width="455" alt="image" src="https://user-images.githubusercontent.com/70627979/182009929-3ec3c589-c287-40ef-a6ec-c0620d3910ea.png">

- 주기적으로 리프레시가 필요
- 비트당 1개 트랜지스터 사용
- 성능 향상을 위해 행을 버퍼링해서 반복적으로 접근 (버퍼는 SRAM처럼 동작)

- 구성
  - Bank:  워드값 만들기 위해 여러 개의 메모리칩을 세트로 구성
  - Pre: Bank open/close
  - Act: 행 주소 참조 (워드 단위)

- SDRAM(synchronous DRAM): DRAM에 클럭을 추가한 것
  - 클럭을 사용하므로 메모리와 프로세서를 동기화하는 시간이 필요 없다
  - 한꺼번에 여러 비트를 전송할 수 있어 속도가 빠름 (→ **DDR**: double data rate, 데이터의 대역폭이 2배)



### 플래시 메모리

: 전기적으로 지울 수 있고, 프로그래밍이 가능한 ROM(EEPROM)의 한 종류

- Disk나 DRAM과 달리, 플래시 메모리의 쓰기는 비트를 마모시킴
- SSD



### 디스크 메모리

- HDD



## 5.3 The Basics of Caches

- 캐시 Index 값과 Tag를 이용해 특정 block address에 대한 내용이 캐시 내에 있는지 파악할 수 있다.

  - **Tag**: 어느 메모리에 매핑된 블럭인지 파악
  - **Valid Bit**: 캐시의 특정 라인에 데이터가 없으면 0, 있으면 1 (init: 0)

  <img width="727" alt="image" src="https://user-images.githubusercontent.com/70627979/182010726-c74ef986-18ed-4004-a896-e6f5d52adbea.png" style="width:67%;" >

- **direct mapped**: 각 메모리의 위치(주소)가 캐시 내의 정확히 한 곳에만 매핑되는 캐시 구조
  - 위 방식을 이용해 탐색



### Cache Misses

1. Stall the CPU pipeline

2. fetch block from next level of hierarchy
   - instruction cache miss → restart instruction fetch
   - data cache miss → complete data access



### Handling Writes

- **Write Through**: 데이터를 캐시와 메모리 동시에 쓰는 방법
- **Write Back**: 캐시 내의 블록에만 쓰고, 캐시에서 제거될 때 메모에 쓰는 방법



## 5.4 Measuring and Improving Cache Performance

- **Average Memory Access Time (AMAT)**
  - Hit time + Miss rate * Miss penalty



### Associative Caches

<img width="490" alt="image" src="https://user-images.githubusercontent.com/70627979/182012022-273eb1d5-c8d4-47a2-bc90-e3d01f8e5939.png">

- **fully associative**: 블록이 캐시 내의 어느 곳에나 들어갈 수 있는 방식
  - 모든 캐시 엔트리를 비교해야하므로, 비용이 비쌈
- **n-way set associative**: 한 블록이 들어갈 수 있는 자리의 개수가 n개인 방식
  - 1개의 집합 내에 n개의 블록
  - set: tag + data



- associativity를 증가시키면, miss rate가 감소
  - 그러나 적중 시간이 증가한다



### Replacement Policy

- LFU(Least Frequently Used)
- LRU(Least Recently Used)



### Multilevel Caches

- 프로세스의 빠른 클럭 속도와 느린 DRAM의 접근시간의 차이를 줄이기 위해, 캐시를 여러 계층으로 지원한다.
- Primary cache는 보통 CPU에 있음
- L-2 캐시는 primary cache에서 miss가 발생하면, 처리함 (L-1보다 크고 느림)
- 더 이상 캐시가 없다면, 메인 메모리에 접근해야함